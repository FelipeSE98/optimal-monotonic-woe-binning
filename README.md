# Optimal Binning with Monotonicity Constraints

## Introduction

This project presents an innovative method to identify optimal binning points under monotonicity constraints for numerical variables. The approach is particularly useful for applications such as credit risk modeling, where Weight of Evidence (WoE) transformation and Information Value (IV) calculation are key components of logistic regression models.

The notebook `usage_guide.ipynb` demonstrates how to apply this method to identify bins that ensure interpretability while maintaining a logical relationship with a binary target variable. It also integrates custom Python functions to automate and streamline the process.

**Note:** This project serves as an illustrative example. No preprocessing or treatment is performed on the variables, and the results should not be used directly for production purposes. However, the methodology and functions demonstrated here can be extrapolated and adapted to real-world problems in various domains requiring monotonic binning and WoE transformations.

---

## Key Features

1. **Innovative Binning Method**:
   - Uses a decision tree algorithm to determine candidate cut points.
   - Evaluates all combinations of candidate points to ensure monotonicity in default rates.

2. **Comprehensive Function Workflow**:
   - Modular functions to handle every step: from generating cut points to calculating WoE and IV.

3. **Customizable Parameters**:
   - Supports special value handling, missing values, and constraints on bin sizes and monotonicity.

---

## Workflow Overview

### 1. **Generate Candidate Cut Points**
   **Function**: `get_powerset_cut_points`  
   - **Description**: 
     Identifies optimal cut points for a given variable using a decision tree classifier with a customizable maximum depth. Generates the power set (excluding the empty set) of all cut points identified by the tree.
   - **Parameters**:
     - `df`: Input DataFrame containing the variable of interest.
     - `variable`: Name of the numerical variable to analyze.
     - `target`: Name of the target column (binary).
     - `special_values`: List of values to exclude from the analysis.
     - `max_depth`: Maximum depth of the decision tree. Default is `3`.
     - `random_state`: Random seed for reproducibility. Default is `2357`.

### 2. **Check Monotonicity**
   **Function**: `get_monotonic_cuts`  
   - **Description**: 
     Detects the set of cut points for which the default rate trend is monotonic (either increasing or decreasing) across the bins generated by each set of cut points.
   - **Parameters**:
     - `df`: Input DataFrame.
     - `variable`: Name of the variable to analyze.
     - `target`: Name of the target column (binary).
     - `powerset`: Power set of cut points generated by `get_powerset_cut_points`.
     - `special_values`: List of special values to exclude.
   - **Output**:
     - Monotonic increasing and decreasing cut points.
     - A dictionary with the monotonicity type for each set.

### 3. **Validate Cut Points**
   **Function**: `get_valid_cuts`  
   - **Description**: 
     Identifies valid sets of cut points that satisfy a desired monotonicity and ensure each bin contains at least a specified percentage of records.
   - **Parameters**:
     - `df`: Input DataFrame.
     - `variable`: Name of the variable.
     - `cuts_increasing`: List of monotonic increasing cut points.
     - `cuts_decreasing`: List of monotonic decreasing cut points.
     - `special_values`: List of special values to exclude.
     - `monotony`: Desired monotonicity (`'increasing'`, `'decreasing'`, or `None`).
     - `min_percentage`: Minimum percentage of records required in each bin. Default is `5`.

### 4. **Select Optimal Cut Points**
   **Function**: `get_best_cuts`  
   - **Description**: 
     Finds the set of cut points with the desired monotonicity that yields the highest IV. Gives priority to sets of cuts that generate the highest number of bins.
   - **Parameters**:
     - `df`: Input DataFrame.
     - `variable`: Name of the variable.
     - `target`: Name of the target column (binary).
     - `special_values`: List of special values to exclude.
     - `valid_cuts`: List of valid sets of cut points.
     - `dict_monotony`: Dictionary mapping cut points to their monotonicity.

### 5. **Calculate WoE and IV**
   **Function**: `calculate_iv`  
   - **Description**: 
     Calculates the Weight of Evidence (WOE) and Information Value (IV) for the given variable. This function assumes that bins or categories are already defined for the variable.
   - **Parameters**:
     - `df`: Input DataFrame.
     - `variable`: Name of the variable.
     - `target`: Name of the target column (binary).
     - `epsilon`: Small constant to avoid division by zero in calculations. Default is `0.00001`.
     - `monotony`: Monotonicity of the evaluated cut points.

### 6. **Transform Variables**
   **Function**: `woe_transform`  
   - **Description**: 
     Transforms a variable into its Weight of Evidence (WOE) representation based on the optimal set of cut points.
   - **Parameters**:
     - `df`: Input DataFrame.
     - `variable`: Name of the variable.
     - `special_values`: List of special values to handle separately.
     - `optim_cuts`: Tuple containing the optimal set of cut points and its summary DataFrame.

---

## Workflow Integration

The functions are designed to work seamlessly together. Here's an example of how they connect:

```python
# Identify candidate cut points
candidate_cuts = get_powerset_cut_points(df, variable, target, special_values)

# Find monotonic cut points
cuts_inc, cuts_dec, monotony_dict = get_monotonic_cuts(df, variable, target, candidate_cuts, special_values)

# Validate and select cuts
valid_cuts = get_valid_cuts(df, variable, cuts_inc, cuts_dec, special_values, monotony='increasing')

# Determine the best cuts
optimal_cuts, iv_scores = get_best_cuts(df, variable, target, special_values, valid_cuts, monotony_dict)

# Calculate WoE and IV
iv, summary_df = calculate_iv(df, 'bin', target)

# Transform variable
df = woe_transform(df, variable, special_values, optimal_cuts)