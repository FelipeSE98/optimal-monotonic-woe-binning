# Import necessary librarys
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from itertools import chain, combinations

# Generate the power set of optimal cut points
def get_powerset_cut_points(
        df,
        variable,
        target,
        special_values,
        max_depth=3,
        random_state=2357
):
    """
    Identifies optimal cut points for a given variable using a decision tree classifier with a customizable maximum depth. The tree uses the Gini impurity criterion to determine the splits. The function generates a power set (excluding the empty set) of all cut points identified by the tree.

    ----------
    Input:
        * df: pandas DataFrame containing the variable of interest and the target column.
        * variable: String representing the name of the variable to analyze.
        * target: String representing the name of target variable.
        * special_values: List or set of special values to exclude from the analysis.
        * max_depth: Integer scpecifying the maximum depth of the decision tree (default is 3).
        * random_state: Integer specifying the seed for pseudo-random number generation (default is the prime number 2357).

    Output:
        List of subsets representing the power set of the identified cut points, excluding the empty set.

    Notes:
        * Both special values and missing values are excluded from the calculation of cut points.
        * The maximum number of cut points is given by:
            n_cuts = 2^{max_depth} - 1
        * The maximum number of categories is given by:
            n_categories = 2^{max_depth}

    ----------
    """

    # Verify that 'df' is a pandas DataFrame
    if not isinstance(df, pd.DataFrame):
        raise ValueError('The input df must be a pandas DataFrame.')
    
    # Verify that 'variable' and 'target' are columns in the DataFrame
    if variable not in df.columns:
        raise ValueError(f'The column {variable} is not in the DataFrame.')
    if target not in df.columns:
        raise ValueError(f'The column {target} is not in the DataFrame.')
    
    # Verify that variable is numeric
    if not pd.api.types.is_numeric_dtype(df[variable]):
        raise ValueError(f'The column {variable} must be numeric.')
    
    # Verify that special_values is a list or a set
    if not isinstance(special_values, (list, set)):
        raise ValueError('The input special_values must be a list or a set.')
    
    # Verify that max_depth is a positive integer
    if not isinstance(max_depth, int) or max_depth <= 0:
        raise ValueError('The input random_state must be a integer.')
    
    # Verify that the DataFrame contains valid data after filtering
    df_valid = df[~df[variable].isin(special_values) & df[variable].notna()]
    if df_valid.empty:
        print('No valid data points remain after filtering special values and missing values.')
        return None
    
    # Proceed with processing
    X = df_valid[[variable]].values
    y = df_valid[target].values

    # Define the decision tree model
    tree = DecisionTreeClassifier(
        criterion = 'gini',
        max_depth = max_depth,
        random_state = random_state
    )

    # Fit the model to the data
    tree.fit(X, y)

    # Extract cut points (thresholds) from the trained decision tree. Thresholds are all the values used to split the data, excluding leaf nodes (-2)
    thresholds = set(tree.tree_.threshold[tree.tree_.threshold != -2])

    # Generate the power set of the identified cut points
    powerset = chain.from_iterable(combinations(thresholds, r) for r in range(len(thresholds) + 1))

    # Return the power set, excluding the empty subset
    return [set(subset) for subset in powerset][1:]

# Obtain only the sets of cuts with monotonic trends
def get_monotonic_cuts(
        df,
        variable,
        target,
        powerset,
        special_values
):
    """
    Detects the set of cut points for wich the default rate trend is monotonic (either increasing or decreasing) across the bins generated by each set of cut points.

    ----------
    Input:
        * df: pandas DataFrame containing the variable of interest and the target column.
        * variable: String representing the name of the variable to analyze.
        * target: String representing the name of the target variable.
        * powerset: Power set of cut points generated by the get_powerset_cut_points function.
        * special_values: List of special values to exclude from de analysis.

    Output:
        * cuts_increasing: List of all sets of cut points with a monotonic increasing trend.
        * cuts_dcreasing: List of all sets of cut points with a monotonic decreasing trend.
        * dict_monotony: Dictionary containing information about the monotonicity of the cuts with a monotonic trend.

    Notes:
        * Special values and missing values are excluded from the analysis when calculating default rates.
        * Monotonicity is determined based on the difference in default rates:
            - Increasing: All differences between consecutive bins are positive.
            - Decreasing: All differences between consecutive bins are negative.
        * The function evaluates all subsets in the power set of cut points.
    ----------
    """

    # Verify that 'df' is a pandas DataFrame
    if not isinstance(df, pd.DataFrame):
        raise ValueError('The input df must be a pandas DataFrame.')
    
    # Verify that 'variable' and 'target' are columns in the DataFrame
    if variable not in df.columns:
        raise ValueError(f'The column {variable} is not in the DataFrame.')
    if target not in df.columns:
        raise ValueError(f'The column {target} is not in the DataFrame.')
    
    # Verify that variable is numeric
    if not pd.api.types.is_numeric_dtype(df[variable]):
        raise ValueError(f'The column {variable} must be numeric.')
    
    # Verify that special_values is a list or a set
    if not isinstance(special_values, (list, set)):
        raise ValueError('The input special_values must be a list or a set.')
    
    # Verify powerset
    if not isinstance(powerset, list) or not all(isinstance(cuts, (list, set)) for cuts in powerset):
        raise ValueError("The input powerset must be a list of lists or sets representing cut points.")
    
    # Inicialize empty lists to store monotonic cut points and an empty dictionary to store monotonicity information
    cuts_increasing = list()
    cuts_decreasing = list()
    dict_monotony = dict()

    # Loop through all subsets of cut points in the powerset
    for cuts in powerset:
        # Define bins based on the cut points
        bins = [-float('inf')] + sorted(cuts) + [float('inf')]

        # Assign each row to a bin based on the variable value
        df['bin'] = pd.cut(df[variable], bins=bins, right=False)

        # Exclude rows with special values or missing values in the variable, and verify that the DataFrame contains valid data after filtering
        df_valid = df[~df[variable].isin(special_values) & df[variable].notna()]
        if df_valid.empty:
            print('No valid data points remain after filtering special values and missing values.')
            del df['bin']
            return None, None, None

        # Calculate the default rate for each bin
        bin_rates = df_valid.groupby('bin', observed=True)[target].mean().reset_index()
        bin_rates['default_rate'] = bin_rates[target]

        # Check for monotonicity in default rates
        differences = bin_rates['default_rate'].diff().dropna()
        monotonic_increasing = all(differences > 0) 
        monotonic_decreasing = all(differences < 0)

        # Store monotonic cut points and their trend
        if monotonic_increasing:
            cuts_increasing.append(sorted(cuts))
            dict_monotony[str(sorted(cuts))] = 'increasing'
        elif monotonic_decreasing:
            cuts_decreasing.append(sorted(cuts))
            dict_monotony[str(sorted(cuts))] = 'decreasing'

    del df['bin']

    # Display the number of monotonic combinations
    print(f"\n{'='*40}")
    print(f"Results for Variable: {variable}")
    print(f"{'-'*40}")
    print(f"Monotonic increasing cuts: {len(cuts_increasing)}")
    print(f"Monotonic decreasing cuts: {len(cuts_decreasing)}")
    print(f"{'='*40}\n")

    return cuts_increasing, cuts_decreasing, dict_monotony

# Obtain valid sets of cut points
def get_valid_cuts(
        df,
        variable,
        cuts_increasing,
        cuts_decreasing,
        special_values,
        monotony=None,
        min_percentage=5
):
    """
    Identifies valid sets of cut points that satify a desired monotonicity and ensure each bin contains at least a specified percentage of records.

    ----------
    Input:
        * df: pandas DataFrame containing the variable of interest.
        * variable: String representing the name of the variable of interest.
        * cuts_increasing: List of lists containing monotonic increasing cut points. (return of get_monotonic_cuts function)
        * cuts_decreasing: List of lists containing monotonic decreasing cut points. (return of get_monotonic_cuts function)
        * special_values: List of special values to exclude from de analysis.
        * monotony: String to enforce a specific monotonicity ('increasing' or 'decreasing'). If None, the function selects the most frequent monotonicity.
        * min_percentage: Minimum percentage of total records required in each bin (default is 5%).

    Output:
        List of valid sets of cut points.
    
    Notes:
        * If no monotonic cut points exist, the function returns 'discard'.
        * If monotonicity is ambiguous and cannot be determined automatically, the function return 'specify_monotony'.
        * If the specified monotony is not found:
            - Returns 'try_decreasing' if 'increasing' cuts are not found.
            - Returns 'try_increasing' if 'decreasing' cuts are not found.
    ----------
    """
    # Discard the variable if it only contains special values and missing data
    if (cuts_increasing is None) and (cuts_decreasing is None):
        print(f'The variable {variable} only contains special values and missing data.')
        print(f"{'='*40}\n")
        return 'discard'
    
    # Verify that 'df' is a pandas DataFrame
    if not isinstance(df, pd.DataFrame):
        raise ValueError('The input df must be a pandas DataFrame.')
    
    # Verify that 'variable' is column in the DataFrame
    if variable not in df.columns:
        raise ValueError(f'The column {variable} is not in the DataFrame.')

    # Verify that variable is numeric
    if not pd.api.types.is_numeric_dtype(df[variable]):
        raise ValueError(f'The column {variable} must be numeric.')

    # Verify list of lists
    if not isinstance(cuts_increasing, list) or not all(isinstance(cut, list) for cut in cuts_increasing):
        raise ValueError("The input `cuts_increasing` must be a list of lists.")

    if not isinstance(cuts_decreasing, list) or not all(isinstance(cut, list) for cut in cuts_decreasing):
        raise ValueError("The input `cuts_decreasing` must be a list of lists.")

    # Verify that special_values is a list or a set
    if not isinstance(special_values, (list, set)):
        raise ValueError('The input special_values must be a list or a set.')
    
    # Verify the correctness of the monotony input and min_percentage input
    if monotony not in {None, 'increasing', 'decreasing'}:
        raise ValueError("The input `monotony` must be one of: None, 'increasing', 'decreasing'.")
    
    if not isinstance(min_percentage, (int, float)) or min_percentage <= 0 or min_percentage > 100:
        raise ValueError("The input `min_percentage` must be a positive number between 0 and 100.")
    
    print(f"\n{'='*40}")
    print(f"Processing Variable: {variable}")
    print(f"{'-'*40}")

    # Get the total number of records 
    N = df.shape[0]

    len_increasing = len(cuts_increasing)
    len_decreasing = len(cuts_decreasing)

    # Exit if no monotonic cut points exist
    if len_increasing == len_decreasing == 0:
        print(f"The variable {variable} has no monotonic cut points and should be discarded.")
        print(f"{'='*40}\n")
        return 'discard'
    
    if monotony is None:
        # If no specific monotonicity is provided, the function attemps to select the most appropiate monotonicity based on the available cut points:
        #   - If only decreasing cuts exist, it will use them.
        #   - If only increasing cuts exist, it will use them.
        #   - If both increasing and decreasing cuts exist, the function will choose the one with more cut points.
        #   - If the number of increasing and decreasing cuts is equal, the function cannot determine the preferred monotonicity and will prompt the user to specify it explicitly by returning 'specify_monotony'.
        if len_increasing == 0 and len_decreasing != 0:
            print("Searching for valid decreasing cuts.")
            monotonic_cuts = cuts_decreasing
        elif len_increasing != 0 and len_decreasing == 0:
            print("Searching for valid increasing cuts.")
            monotonic_cuts = cuts_increasing
        elif len_increasing > len_decreasing:
            print("Searching for valid increasing cuts.")
            monotonic_cuts = cuts_increasing
        elif len_increasing < len_decreasing:
            print("Searching for valid decreasing cuts.")
            monotonic_cuts = cuts_decreasing
        else:
            print("Please specify the monotony to search for valid cuts.")
            print(f"{'='*40}\n")
            return 'specify_monotony'
        
    elif monotony == 'increasing':
        if len_increasing == 0:
            print("No monotonic increasing cuts found. Try 'decreasing'.")
            print(f"{'='*40}\n")
            return 'try_decreasing'
        else:
            monotonic_cuts = cuts_increasing
    elif monotony == 'decreasing':
        if len_decreasing == 0:
            print("No monotonic decreasing cuts found. Try 'increasing'.")
            print(f"{'='*40}\n")
            return 'try_increasing'
        else:
            monotonic_cuts = cuts_decreasing

    # Identify valid cuts
    valid_cuts = []
    for cuts in monotonic_cuts:
        # Define bins based on the cut points
        bins = [-float('inf')] + sorted(cuts) + [float('inf')]
        df['bin'] = pd.cut(df[variable], bins=bins, right=False)

        # Exclude bins containing special values
        df_valid = df[~df[variable].isin(special_values) & df[variable].notna()]

        # Check if each bin has at least `min_percentage` of records
        is_valid = all((df_valid.groupby('bin')['bin'].count() / N) * 100 >= min_percentage)

        if is_valid:
            valid_cuts.append(sorted(cuts))

    # Try to find the maximum length of valid cuts
    try:
        max_length = len(max(valid_cuts, key=len))
        valid_cuts = [cut for cut in valid_cuts if len(cut) == max_length]
    except ValueError:  # If no valid cuts are found
        max_length = None

    # Display results
    if valid_cuts:
        print(f"Valid cuts identified for variable {variable}: {len(valid_cuts)} sets.")
    else:
        print(f"No valid cuts meet the {min_percentage}% threshold for variable {variable}.")
    print(f"{'='*40}\n")

    del df['bin']

    # Return valid cuts
    return valid_cuts

def calculate_iv(
        df,
        variable,
        target,
        epsilon=0.00001,
        monotony=None
):
    """
    Calculates the Weight of Evidence (WOE) and Information Value (IV) for the given variable. This function assumes that bins or categories are already defined for the variable.

    ----------
    Input:
        * df: pandas DataFrame containing the variable of interest and the target column.
        * variable: String representing the name of the variable of interest.
        * target: String representing the name of the target column.
        * epsilon: Small constant to avoid division by zero in the WOE calculation (default: 0.00005)
        * monotony: String indicating the monotonicity of the cuts being evaluated. This is only applicable for numerical variables. If not provided, the variable is assumed to be categorical.

    Output:
        * total_iv: the total Information Value (IV) of the variable.
        * grouped: A summary DataFrame containing the components required to calculate WOE and perform analysis.

    Notes:
        * WOE (Weight of Evidence) is calculated as:
                WOE = ln((proportion of non-events in bin) / (proportion of events in bin))
            where proportions are adjusted with `epsilon` to avoid division by zero.
        * IV (Information Value) is the sum of:
              IV = (proportion of non-events - proportion of events) * WOE
            across all bins/categories.
        * The function will raise a ValueError if the inputs are invalid.
        * The `grouped` DataFrame includes the WOE, IV, and default rate for each bin/category.
    ----------
    """
    # Validate inputs
    if not isinstance(df, pd.DataFrame):
        raise ValueError("The input `df` must be a pandas DataFrame.")

    if variable not in df.columns:
        raise ValueError(f"The column `{variable}` is not in the DataFrame.")

    if target not in df.columns:
        raise ValueError(f"The column `{target}` is not in the DataFrame.")

    if not pd.api.types.is_numeric_dtype(df[target]):
        raise ValueError(f"The column `{target}` must contain numeric data (binary target expected).")

    if not isinstance(epsilon, (int, float)) or epsilon <= 0:
        raise ValueError("The input `epsilon` must be a positive number.")

    if monotony not in {None, 'increasing', 'decreasing', 'categorical'}:
        raise ValueError("The `monotony` parameter must be one of: None, 'increasing', 'decreasing', 'categorical'.")
    
    # Group data by the variable of interest and calculate counts and sums
    grouped = (
        df.groupby(variable)[target]
        .agg(['count', 'sum'])
        .reset_index()
        .rename(columns={'count': 'total', 'sum': 'event'})
    )
    grouped['non_event'] = grouped['total'] - grouped['event']

    # Calculate the total events and non-events for the proportions
    total_event = grouped['event'].sum()
    total_non_event = grouped['non_event'].sum()

    if total_event == 0 or total_non_event == 0:
        raise ValueError("The target variable must contain both events (1) and non-events (0).")
    
    # Calculate event and non-event rates for each bin
    grouped['event_rate'] = grouped['event'] / total_event
    grouped['non_event_rate'] = grouped['non_event'] / total_non_event

    # Calculate the default rate for each bin
    grouped['default_rate'] = grouped['event'] / grouped['total']

    # Calculate WOE and IV for each bin
    grouped['woe'] = np.log(
        grouped['non_event_rate'].replace(0, epsilon) / grouped['event_rate'].replace(0, epsilon)
    )
    grouped['iv'] = grouped['woe'] * (grouped['non_event_rate'] - grouped['event_rate'])

    # Add monotony to the summary DataFrame
    grouped['monotony'] = monotony if monotony else 'categorical'

    # Calculate total IV
    total_iv = grouped['iv'].sum()

    return total_iv, grouped

def get_best_cuts(
        df,
        variable,
        target,
        special_values,
        valid_cuts,
        dict_monotony
):
    """
    Finds the set of cut points with the desired monotonicity that yields the highest IV. Gives priority to sets of cuts that generate the highest number of bins.

    ----------
    Input:
        * df: pandas DataFrame containing the variable of interest.
        * variable: String representing the name of the variable of interest.
        * target: String representing the name of the target variable.
        * special_values: List of special values to be considered separately. 
        * valid_cuts: List of valid sets of cut points.
        * dict_monotony: Dictionary mapping each set of monotonic cut points to its monotonicity.

    Output:
        * optim_cuts: Tuple containing the optimal set of cut points, its IV score, and summary DataFrame.
        * iv_scores: List of tuples containing all analyzed cut points, their IV scores, and respective summaries.

    Notes:
        * Special values are assigned their own bins labeled as `Special_<value>`.
        * Missing values are assigned to a separate bin labeled `Missing`.
    ----------
    """
    # Validate inputs
    if not isinstance(df, pd.DataFrame):
        raise ValueError("The input `df` must be a pandas DataFrame.")

    if variable not in df.columns:
        raise ValueError(f"The column `{variable}` is not in the DataFrame.")

    if target not in df.columns:
        raise ValueError(f"The column `{target}` is not in the DataFrame.")

    if not isinstance(valid_cuts, list) or not all(isinstance(cut, list) for cut in valid_cuts):
        raise ValueError("The input `valid_cuts` must be a list of lists.")

    if not isinstance(special_values, (list, set)):
        raise ValueError("The input `special_values` must be a list or set.")

    if not isinstance(dict_monotony, dict):
        raise ValueError("The input `dict_monotony` must be a dictionary.")
    
    # Initialize a list to store IV scores and summaries for all valid cuts
    iv_scores = []

    for cuts in valid_cuts:
        # Define bins based on the current set of cut points
        bins = [-float('inf')] + sorted(cuts) + [float('inf')]
        df['bin'] = pd.cut(df[variable], bins=bins, right=False)

        # Assign special bins for special values
        for value in special_values:
            df['bin'] = np.where(df[variable] == value, f'Special_{value}', df['bin'])

        # Assign a separate bin for missing values
        df['bin'] = np.where(df[variable].isna(), 'Missing', df['bin'])

        # Calculate IV for the current set of cut points
        monotony = dict_monotony.get(str(sorted(cuts)), None)
        iv, resume_df = calculate_iv(df, 'bin', target=target, monotony=monotony)

        # Store the results in iv_scores
        iv_scores.append((cuts, iv, resume_df))

    # Find the set of cut points with the highest IV score
    optim_cuts = max(iv_scores, key=lambda x: x[1])  # Sort by IV score

    del df['bin']

    # Return the optimal cut points and all scores
    return optim_cuts, iv_scores

def woe_transform(
        df,
        variable,
        special_values,
        optim_cuts
):
    """
    Transforms a variable into its Weight of Evidence (WOE) representation 
    based on the optimal set of cut points.

    ----------
    Input:
        - df: pandas DataFrame containing the variable of interest.
        - variable: String representing the name of the variable to transform.
        - special_values: List of special values to be assigned separate bins.
        - optim_cuts: Tuple containing the optimal set of cut points and its summary DataFrame.

    Output:
        - df: DataFrame with the original data and the WOE-transformed variable added.

    Notes:
        - Missing values are assigned to a separate bin labeled as 'Missing'.
        - Special values are assigned to bins labeled as `Special_<value>`.
        - The new WOE-transformed variable is named `woe_<variable>`.
    ----------
    """
    # Validate inputs
    if not isinstance(df, pd.DataFrame):
        raise ValueError("The input `df` must be a pandas DataFrame.")

    if variable not in df.columns:
        raise ValueError(f"The column `{variable}` is not in the DataFrame.")

    if not isinstance(optim_cuts, tuple) or len(optim_cuts) < 2:
        raise ValueError("The input `optim_cuts` must be a tuple containing cuts and a summary DataFrame.")

    if not isinstance(special_values, (list, set)):
        raise ValueError("The input `special_values` must be a list or set.")
    
    # Extract the optimal set of cut points
    cuts = optim_cuts[0]

    if not isinstance(cuts, list):
        raise ValueError("The first element of `optim_cuts` must be a list of cut points.")
    
    # Extract the summary DataFrame
    resume_df = optim_cuts[-1]

    if not isinstance(resume_df, pd.DataFrame):
        raise ValueError("The last element of `optim_cuts` must be a pandas DataFrame.")
    
    # Define bins based on the optimal cut points
    bins = [-float('inf')] + sorted(cuts) + [float('inf')]
    df['bin'] = pd.cut(df[variable], bins=bins, right=False)

    # Assign special bins for special values
    for value in special_values:
        df['bin'] = np.where(df[variable] == value, f'Special_{value}', df['bin'])

    # Assign a separate bin for missing values
    df['bin'] = np.where(df[variable].isna(), 'Missing', df['bin'])

    # Create a dictionary to map bins to WOE values
    woe_dict = resume_df.set_index('bin')['woe'].to_dict()

    # Map WOE values to the DataFrame
    df['woe_' + variable] = df['bin'].map(woe_dict)

    del df['bin']

    # Return the DataFrame with the WOE-transformed variable
    return df